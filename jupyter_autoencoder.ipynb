{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 10000, 64, 64)\n",
      "(64, 64)\n",
      "(20, 10000, 4096)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbce00a14a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "data = np.load('/home/stud/wangc/lab/mnist_test_seq.npy')\n",
    "print(data.shape)\n",
    "print(data[0,0].shape)\n",
    "data = np.around(data/255,decimal=5)\n",
    "plt.imshow(data[0,0,:,:])\n",
    "data = data.reshape(data.shape[0],data.shape[1],-1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_state LSTMStateTuple(c=<tf.Tensor 'encode/rnn/while/Exit_2:0' shape=(?, 2000) dtype=float32>, h=<tf.Tensor 'encode/rnn/while/Exit_3:0' shape=(?, 2000) dtype=float32>)\n",
      "output shape TensorShape([Dimension(50), Dimension(2000)])\n",
      "before stack shape TensorShape([Dimension(50), Dimension(2000)])\n",
      "projected shape TensorShape([Dimension(20), Dimension(50), Dimension(4096)])\n",
      "reversed shape TensorShape([Dimension(20), Dimension(50), Dimension(4096)])\n",
      "Initialized\n"
     ]
    }
   ],
   "source": [
    "hidden_num = 2000\n",
    "maxtime = 20\n",
    "batch_size = 50\n",
    "frame_size = 64\n",
    "desired = frame_size*frame_size\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    enc_inputs = tf.placeholder(tf.float32, shape = [maxtime, batch_size, desired], name='enc_inputs')\n",
    "\n",
    "    with tf.variable_scope('encode', reuse=None):\n",
    "        enc_cell = tf.contrib.rnn.LSTMCell(hidden_num)\n",
    "        _, enc_state = tf.nn.dynamic_rnn(enc_cell, enc_inputs, dtype=tf.float32, time_major=True)\n",
    "        print('enc_state %r' % (enc_state,))\n",
    "\n",
    "\n",
    "    saved_output = tf.Variable(tf.zeros([batch_size, hidden_num]), trainable=False)\n",
    "    saved_state = tf.Variable(tf.zeros([batch_size, hidden_num]), trainable=False)\n",
    "\n",
    "    # projection weights and biases.\n",
    "    w = tf.Variable(tf.truncated_normal([hidden_num, desired], -0.1, 0.1, dtype=tf.float32), name='w')\n",
    "    b = tf.Variable(tf.zeros([desired]),name='b', dtype=tf.float32)\n",
    "\n",
    "    outputs = list()\n",
    "    output = saved_output\n",
    "    state = saved_state\n",
    "    dec_inputs = tf.zeros([batch_size, desired])\n",
    "    dec_state = enc_state\n",
    "\n",
    "    with tf.variable_scope('dec_scope',reuse=None):\n",
    "        dec_cell = tf.contrib.rnn.LSTMCell(hidden_num)\n",
    "        v = None\n",
    "        for _ in range(maxtime):\n",
    "            with tf.variable_scope('unrolling', reuse=v):\n",
    "                output, dec_state = dec_cell(dec_inputs, dec_state)\n",
    "                if v == None:\n",
    "                    print('output shape %r' % (output.shape,))\n",
    "                v = True\n",
    "                outputs.append(output)\n",
    "\n",
    "    # State saving across unrollings.\n",
    "    with tf.control_dependencies([saved_output.assign(output),\n",
    "                                    saved_state.assign(state)]):\n",
    "        print('before stack shape %r' % (outputs[0].shape))       \n",
    "        outputs = [tf.matmul(i, w) + b for i in outputs]\n",
    "        outputs = tf.stack(outputs)\n",
    "        print('projected shape %r' % (outputs.shape,))\n",
    "        reversed_outputs = outputs[::-1]\n",
    "        print('reversed shape %r' % (reversed_outputs.shape,))\n",
    "        loss = tf.reduce_mean(tf.squared_difference(reversed_outputs,enc_inputs))\n",
    "    # Optimizer.\n",
    "    global_step = tf.Variable(0, trainable = False)\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "            0.1, global_step, 12000, 0.9, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "    optimizer = optimizer.apply_gradients(\n",
    "            zip(gradients, v), global_step=global_step)\n",
    "    saver = tf.train.Saver()\n",
    "    #create summary for loss\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    #tf.summary.tensor_summary('gradients', gradients)\n",
    "    #tf.summary.tensor_summary('projection_weights', w)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "train_size = 9000\n",
    "epoch = 10000\n",
    "steps = int(train_size/batch_size)\n",
    "#summary_frequency = 5\n",
    "\n",
    "\n",
    "restore = False\n",
    "with tf.Session(graph=graph) as session:\n",
    "    if restore==False:\n",
    "        tf.global_variables_initializer().run()\n",
    "        writer = tf.summary.FileWriter('logdir', graph)\n",
    "        print('Initialized')\n",
    "        for _ in range(epoch):\n",
    "            for i in range(steps):\n",
    "                _,l,_,summary = session.run([optimizer, loss, learning_rate, summary_op], feed_dict={enc_inputs:(data[:,i*batch_size:(i+1)*batch_size])})\n",
    "                writer.add_summary(summary, epoch*steps+i)\n",
    "        saver.save(session,\"./model.ckpt\")\n",
    "        writer.close()\n",
    "    else:\n",
    "        saver.restore(session, \"./model.ckpt\")\n",
    "        print(\"model restored\")\n",
    "        val_outputs, l, wo, bo = session.run([outputs, loss, w, b], feed_dict={enc_inputs:data[:,0:batch_size]})\n",
    "        print('outputs shape %r' % (val_outputs.shape,))\n",
    "        print(\"validate error %f\" % l)\n",
    "        for j in range(2):\n",
    "            tmp_in = data[j*(-1)-1,0]\n",
    "            plt.figure()\n",
    "            plt.imshow(tmp_in.reshape(64,-1))\n",
    "            tmp_out = val_outputs[j,0,:]\n",
    "            plt.figure()\n",
    "            plt.imshow(tmp_out.reshape(64,-1))\n",
    "        test_outputs, test_l, _, _ = session.run([outputs, loss, w, b], feed_dict={enc_inputs:data[:,9000:9000+batch_size]})\n",
    "        print(\"test error %f\" % test_l)\n",
    "        for j in range(2):\n",
    "            tmp_in = data[j*(-1)-1,9000]\n",
    "            plt.figure()\n",
    "            plt.imshow(tmp_in.reshape(64,-1))\n",
    "            tmp_out = test_outputs[j,0,:]\n",
    "            plt.figure()\n",
    "            plt.imshow(tmp_out.reshape(64,-1))\n",
    "    print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "Jupyter.notebook.session.delete();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
